# 中国政府养老政策文件爬虫项目实施方案

## 🎯 项目目标

创建一个专门抓取中国政府养老政策文件的爬虫系统，覆盖中央政府和各省级政府的政策文档，为养老政策研究提供数据支持。

## 📊 数据字段设计

### 核心字段
- `policy_title` - 政策标题
- `content` - 正文内容
- `publish_date` - 发布时间
- `publish_agency` - 发布机构
- `document_type` - 文件类型（通知、意见、办法、规定等）

### 扩展字段
- `document_number` - 文件编号
- `policy_level` - 政策级别（中央/省级/市级）
- `province` - 省份（省级政策适用）
- `keywords` - 关键词标签
- `source_url` - 原文链接
- `crawl_date` - 抓取时间
- `file_format` - 文档格式（HTML/PDF/DOC等）
- `policy_status` - 政策状态（有效/废止/修订）

## 🏗️ 项目架构

```
productPolicy/
├── config/                    # 配置文件
│   ├── crawler_config.py     # 爬虫配置
│   └── database_config.py    # 数据库配置
├── src/                      # 源代码
│   ├── models/              # 数据模型
│   │   └── policy_model.py  # 政策文档模型
│   ├── crawlers/            # 爬虫模块
│   │   ├── base_crawler.py  # 基础爬虫类
│   │   ├── national_crawler.py # 中央政府爬虫
│   │   └── provincial_crawler.py # 省级政府爬虫
│   ├── data_processor/      # 数据处理模块
│   │   ├── text_cleaner.py  # 文本清洗
│   │   └── data_validator.py # 数据验证
│   ├── storage/             # 数据存储模块
│   │   ├── excel_writer.py  # Excel文件写入
│   │   └── database_handler.py # 数据库操作
│   └── utils/               # 工具模块
│       ├── request_handler.py # 请求处理
│       └── date_parser.py   # 日期解析
├── data/                    # 数据存储目录
│   ├── raw/                # 原始数据
│   ├── processed/          # 处理后数据
│   └── excel/              # Excel输出文件
├── logs/                   # 日志文件
├── tests/                  # 测试文件
├── requirements.txt        # 依赖包
├── databaseinfo.md        # 数据库信息记录
├── 项目实施方案.md        # 本文档
└── main.py                # 主程序入口
```

## 🛠️ 技术选型

### 核心技术栈
- **Python 3.8+** - 主要开发语言
- **playwright MCP** - 网页浏览和数据抓取（优先使用）
- **requests/httpx** - 备用HTTP请求处理
- **BeautifulSoup4/lxml** - HTML解析
- **pandas** - 数据处理
- **openpyxl** - Excel文件操作
- **sqlite3** - 本地数据库（用于断点续传）
- **loguru** - 日志记录

### 优势特性
- **高效抓取**: 使用playwright MCP，比selenium更快速
- **断点续传**: 支持程序中断后继续抓取
- **高频保存**: 每5条数据自动保存，防止数据丢失
- **智能重试**: 三级重试机制应对网络问题
- **易识别命名**: 文件名包含时间戳和来源标识

## 📂 数据文件命名规范

```
养老政策_中央政府_YYYYMMDD_HHMMSS.xlsx
养老政策_[省份名]_YYYYMMDD_HHMMSS.xlsx
养老政策_全国汇总_YYYYMMDD_HHMMSS.xlsx

示例：
养老政策_中央政府_20241215_143052.xlsx
养老政策_北京市_20241215_143052.xlsx
养老政策_全国汇总_20241215_143052.xlsx
```

## 🔄 可靠性保障机制

### 1. 高频数据保存策略
- **增量保存**: 每抓取5条数据自动保存一次
- **实时备份**: 数据同时保存到数据库和Excel文件
- **进度跟踪**: 维护详细的抓取进度记录

### 2. 网络错误处理
- **三级重试机制**: 
  - 立即重试（网络瞬断）
  - 延迟重试（服务器繁忙）
  - 跳过记录（持续失败）
- **超时控制**: 30秒超时自动重试
- **智能延迟**: 随机延迟1-3秒，避免被限制

### 3. 程序中断恢复
- **状态持久化**: 抓取状态实时保存到SQLite数据库
- **断点续传**: 程序重启后自动从中断位置继续
- **重复检测**: 自动跳过已抓取的文档

## 📋 实施步骤

### 第一阶段：基础框架搭建 ✅
- [x] 创建项目目录结构
- [x] 配置开发环境和依赖包
- [x] 实现基础爬虫类和工具模块
- [x] 建立数据模型和存储机制

### 第二阶段：中央政府爬虫开发 🚀
- [ ] 使用playwright MCP分析目标网站
- [ ] 实现中央政府政策爬虫
- [ ] 数据清洗和验证功能
- [ ] Excel数据导出测试

### 第三阶段：省级政府爬虫开发
- [ ] 研究各省政府网站结构差异
- [ ] 实现通用省级政府爬虫框架
- [ ] 批量配置各省网站参数
- [ ] 统一数据格式处理

### 第四阶段：优化和扩展
- [ ] 性能优化和并发处理
- [ ] 定时任务调度系统
- [ ] 数据质量监控
- [ ] 可视化管理界面

## 🎯 目标网站

### 中央政府
- **URL**: https://sousuo.www.gov.cn/zcwjk/policyDocumentLibrary?t=zhengcelibrary&q=%E5%85%BB%E8%80%81
- **特点**: 统一的政策文档库，结构相对标准化
- **预期数据量**: 500-1000条政策文档

### 省级政府（后续扩展）
- 覆盖31个省级行政区
- 每个省份预计100-300条相关政策
- 总预期数据量: 3000-10000条

## 📊 数据质量控制

### 数据完整性检查
- 必填字段验证（标题、内容、发布机构）
- URL有效性验证
- 时间格式标准化

### 数据去重机制
- 基于文件编号去重
- 基于标题和内容相似度去重
- 跨省份数据合并处理

### 数据清洗规则
- HTML标签清理
- 特殊字符处理
- 文本格式统一化

## 🔍 监控和日志

### 日志记录
- **爬取进度**: 实时记录抓取页面和文档数量
- **错误日志**: 详细记录网络错误和解析异常
- **性能监控**: 记录抓取速度和响应时间

### 报告生成
- 每日抓取报告
- 数据质量分析报告
- 异常情况汇总报告

## 📅 项目时间线

- **第1天**: 基础框架搭建 ✅
- **第2-3天**: 中央政府爬虫开发和测试
- **第4-7天**: 省级政府爬虫开发
- **第8-10天**: 系统优化和测试
- **第11-14天**: 数据质量优化和文档完善

## 🚀 立即执行计划

当前状态：**第一阶段已完成**，即将开始第二阶段

**下一步行动**：
1. 创建项目文件结构
2. 使用playwright MCP分析中央政府网站
3. 实现并测试中央政府爬虫
4. 进行首次数据抓取验证

---

*文档创建时间: 2024-12-15*  
*最后更新: 2024-12-15* 