#!/usr/bin/env python3
"""
æ”¿ç­–çˆ¬è™«ä¸»ç¨‹åº
ä½¿ç”¨Playwright MCPè¿›è¡Œç½‘é¡µæŠ“å–
"""
import sys
import os
import asyncio
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(str(Path(__file__).parent))

from loguru import logger
from src.crawlers.national_crawler import NationalCrawler

class PolicyCrawlerMain:
    """æ”¿ç­–çˆ¬è™«ä¸»ç¨‹åº"""
    
    def __init__(self):
        self.national_crawler = None
        self.setup_logging()
    
    def setup_logging(self):
        """è®¾ç½®å…¨å±€æ—¥å¿—"""
        logger.remove()  # ç§»é™¤é»˜è®¤handler
        logger.add(
            sys.stdout,
            format="<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level: <8}</level> | <cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> - <level>{message}</level>",
            level="INFO"
        )
        logger.add(
            "logs/main_{time:YYYYMMDD}.log",
            rotation="00:00",
            retention="30 days",
            format="{time:YYYY-MM-DD HH:mm:ss} | {level: <8} | {name}:{function}:{line} - {message}",
            level="DEBUG"
        )
        logger.info("æ”¿ç­–çˆ¬è™«ç¨‹åºå¯åŠ¨")
    
    def run_with_playwright_mcp(self, page):
        """ä½¿ç”¨Playwright MCPé¡µé¢å¯¹è±¡è¿è¡Œçˆ¬è™«"""
        try:
            logger.info("å¼€å§‹ä½¿ç”¨Playwright MCPçˆ¬å–ä¸­å¤®æ”¿åºœæ”¿ç­–")
            
            # åˆå§‹åŒ–çˆ¬è™«
            self.national_crawler = NationalCrawler()
            self.national_crawler.set_playwright_page(page)
            
            # å¼€å§‹çˆ¬å–
            self.national_crawler.crawl()
            
            logger.info("çˆ¬å–ä»»åŠ¡å®Œæˆ")
            return True
            
        except Exception as e:
            logger.error(f"çˆ¬å–è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
            return False
    
    def get_start_url(self):
        """è·å–èµ·å§‹URL"""
        from config.crawler_config import config
        params = config.NATIONAL_CONFIG["search_params"]
        base_url = config.NATIONAL_CONFIG["base_url"]
        
        # æ„å»ºåˆå§‹æœç´¢URL
        param_string = "&".join([f"{k}={v}" for k, v in params.items()])
        start_url = f"{base_url}?{param_string}&p=1&n=10"
        
        logger.info(f"èµ·å§‹URL: {start_url}")
        return start_url

def main():
    """ä¸»å‡½æ•° - ç‹¬ç«‹è¿è¡Œæ¨¡å¼"""
    logger.info("ç‹¬ç«‹è¿è¡Œæ¨¡å¼å¯åŠ¨")
    crawler_main = PolicyCrawlerMain()
    
    print("=" * 50)
    print("ğŸš€ æ”¿ç­–çˆ¬è™«ç¨‹åº")
    print("=" * 50)
    print("ğŸ“‹ ä½¿ç”¨è¯´æ˜ï¼š")
    print("1. æœ¬ç¨‹åºéœ€è¦é…åˆPlaywright MCPä½¿ç”¨")
    print("2. è¯·ä½¿ç”¨ä»¥ä¸‹URLå¼€å§‹çˆ¬å–ï¼š")
    print(f"   {crawler_main.get_start_url()}")
    print("3. æ•°æ®å°†ä¿å­˜åˆ°data/excel/ç›®å½•ä¸‹")
    print("=" * 50)
    
    return crawler_main

if __name__ == "__main__":
    main_instance = main() 